import os 
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict
from serp_search import search
from tools import ToolExecutor
import re

load_dotenv()

REACT_PROMPT_TEMPLATE = """
è¯·æ³¨æ„ï¼Œä½ æ˜¯ä¸€ä¸ªæœ‰èƒ½åŠ›è°ƒç”¨å¤–éƒ¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

å¯ç”¨å·¥å…·å¦‚ä¸‹:
{tools}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿›è¡Œå›åº”:

Thought: ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç”¨äºåˆ†æé—®é¢˜ã€æ‹†è§£ä»»åŠ¡å’Œè§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
Action: ä½ å†³å®šé‡‡å–çš„è¡ŒåŠ¨ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€:
- `{{tool_name}}[{{tool_input}}]`:è°ƒç”¨ä¸€ä¸ªå¯ç”¨å·¥å…·ã€‚
- `Finish[æœ€ç»ˆç­”æ¡ˆ]`:å½“ä½ è®¤ä¸ºå·²ç»è·å¾—æœ€ç»ˆç­”æ¡ˆæ—¶ã€‚
- å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨Action:å­—æ®µåä½¿ç”¨ finish(answer="...") æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

ç°åœ¨ï¼Œè¯·å¼€å§‹è§£å†³ä»¥ä¸‹é—®é¢˜:
Question: {question}
History: {history}
"""

class HelloAgentsLLM:
    """
    Design LLM class to enable it to call any openai-based services and 
    use streaming services as default
    """

    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT", "60"))

        if not all([self.model, apiKey, baseUrl]):
            raise ValueError("Model, API key or Base Url must be provided either as arguments or environment variables.")
        
        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        Method to call OpenAI chat completion with streaming support
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True
            )

            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end='', flush=True)
                collected_content.append(content)
            print()  # for newline after streaming
            return ''.join(collected_content)
        
        except Exception as e:
            print("âŒ å¤§è¯­è¨€æ¨¡å‹å“åº”å¤±è´¥:", str(e))
            return None 
        
class ReActAgent:
    def __init__(self, llmClient: HelloAgentsLLM, toolExecutor: ToolExecutor, maxSteps: int = 5):
        self.llmClient = llmClient
        self.toolExecutor = toolExecutor
        self.maxSteps = maxSteps
        self.history = []
    
    def _parse_output(self, text: str):
        """
        ç®€å•è§£æ LLM è¾“å‡ºï¼Œæå– Thought å’Œ Action
        """
        thought_match = re.search(r"Thought: (.*)", text)
        action_match = re.search(r"Action: (.*)", text)
        thought = thought_match.group(1).strip() if thought_match else None
        action = action_match.group(1).strip() if action_match else None
        return thought, action

    def _parse_action(self, action_text: str):
        """è§£æActionå­—ç¬¦ä¸²ï¼Œæå–å·¥å…·åç§°å’Œè¾“å…¥ã€‚"""
        match = re.match(r"(\w+)\[(.*)\]", action_text)
        if match:
            return match.group(1), match.group(2)
        return None, None
            

    def run(self, question: str):
        self.history = []
        current_step = 0

        while current_step < self.maxSteps:
            current_step += 1
            print(f"\n--- ç¬¬ {current_step} æ­¥ ---")

            # format prompt
            tool_desc = self.toolExecutor.getAvailableTools()
            history_str = "\n".join(self.history)
            prompt = REACT_PROMPT_TEMPLATE.format(
                tools=tool_desc,
                question=question,
                history=history_str
            )

            messages = [
                {"role": "user", "content": prompt}
            ]

            response_text = self.llmClient.think(messages=messages)

            if not response_text:
                print("LLM æœªè¿”å›ä»»ä½•å“åº”ï¼Œç»ˆæ­¢æ‰§è¡Œã€‚")
                break
            
            thought, action = self._parse_output(response_text)

            if thought:
                print(f"æ€è€ƒ: {thought}")

            if not action:
                print("è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                break
            
            # è§£æå¹¶æ‰§è¡Œ Action
            if action.startswith("Finish"):
                # if the action is Finish, extract the final answer
                final_ansnwer = re.match(r"Finish\[(.*)\]", action).group(1)
                print(f"æœ€ç»ˆç­”æ¡ˆ: {final_ansnwer}")
                return final_ansnwer
            
            tool_name, tool_input = self._parse_action(action)
            if not tool_name or not tool_input:
                print("è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                continue

            print(f"ğŸ¬ è¡ŒåŠ¨: {tool_name}[{tool_input}]")
            tool_function = self.toolExecutor.getTool(tool_name)
            if not tool_function:
                observation = f"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚"
            
            else:
                observation = tool_function(tool_input)

                print(f"ğŸ” è§‚å¯Ÿç»“æœ: {observation}")

                self.history.append(f"Action: {action}")
                self.history.append(f"Observation: {observation}")
            
            # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°ï¼Œç»ˆæ­¢æ‰§è¡Œ
        print("å·²è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°ï¼Œç»ˆæ­¢æ‰§è¡Œã€‚")
        return None


# # --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---
# if __name__ == '__main__':
#     try:
#         llmClient = HelloAgentsLLM()
        
#         exampleMessages = [
#             {"role": "system", "content": "You are a helpful assistant that writes Python code."},
#             {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
#         ]
        
#         print("--- è°ƒç”¨LLM ---")
#         responseText = llmClient.think(exampleMessages)
#         if responseText:
#             print("\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---")
#             print(responseText)

#     except ValueError as e:
#         print(e)

# --- å·¥å…·åˆå§‹åŒ–ä¸ä½¿ç”¨ç¤ºä¾‹ ---
# if __name__ == '__main__':
#     toolExecutor = ToolExecutor()
    
#     # æ³¨å†Œæœç´¢å·¥å…·
#     search_description = "ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚"
#     toolExecutor.registerTool(
#         name="serp_search",
#         description=search_description,
#         func=search
#     )
    
#     # å±•ç¤ºå¯ç”¨å·¥å…·
#     print("\n--- å¯ç”¨å·¥å…·åˆ—è¡¨ ---")
#     print(toolExecutor.getAvailableTools())
    
#     # æ™ºèƒ½ä½“çš„Actionè°ƒç”¨ï¼Œè¿™æ¬¡æˆ‘ä»¬é—®ä¸€ä¸ªå®æ—¶æ€§çš„é—®é¢˜
#     print("\n--- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---")
#     tool_name = "serp_search"
#     tool_inpuit = "Whjat is the latest GPU model from Nvidia?"

#     tool_function = toolExecutor.getTool(tool_name)
#     if tool_function:
#         observation = tool_function(tool_inpuit)
#         print(f"\n--- å·¥å…·è§‚å¯Ÿç»“æœ ---\n{observation}")
#         print(observation)

#     else:
#         print(f"å·¥å…· '{tool_name}' æœªæ‰¾åˆ°ã€‚")

if __name__ == "__main__":
    # 1) åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨
    toolExecutor = ToolExecutor()
    toolExecutor.registerTool(
        name="serp_search",
        description="ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚",
        func=search
    )

    # 2) åˆå§‹åŒ– LLM
    llmClient = HelloAgentsLLM()

    # 3) åˆå§‹åŒ– ReAct Agent
    agent = ReActAgent(llmClient=llmClient, toolExecutor=toolExecutor, maxSteps=5)

    # 4) è¿è¡Œæµ‹è¯•é—®é¢˜ï¼ˆå°½é‡é€‰â€œå¿…é¡»æŸ¥å®æ—¶â€çš„ï¼‰
    question = "åä¸ºæœ€æ–°æ‰‹æœºå‹å·åŠä¸»è¦å–ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
    answer = agent.run(question)

    print("\n=== Agent è¿”å› ===")
    print(answer)